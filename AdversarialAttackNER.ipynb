{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These class functions are the adversarial attack systems for NER; if entities == True an entity attack is performed, if entities == False an entity context attack is performed. It has options for performing a Random Attack (default is set to False). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import criteria\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import torch\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "from utils_ner import convert_examples_to_features, get_labels, read_examples_from_file\n",
    "\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "from transformers import WEIGHTS_NAME, BertConfig, BertForTokenClassification, BertTokenizer\n",
    "# from transformers import RobertaConfig, RobertaForTokenClassification, RobertaTokenizer\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for token classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            words: list. The words of the sequence.\n",
    "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.words = words\n",
    "        self.labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialBERT(): \n",
    "    def __init__(self):\n",
    "        ##can uncomment to use a cache version of the USE\n",
    "#         nw_cache_path = '/data/dirksonar/NER_data/42480c3c7f42bf87d36d4c58fc4374b08dae2909/'\n",
    "        self.embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        self.stop_words_set = self.get_stopwords()\n",
    "        self.set_seed(1, 0)\n",
    "        \n",
    "    def initialize_essential(self, entities):\n",
    "        if entities == True: \n",
    "            pass\n",
    "            \n",
    "        if entities == False: \n",
    "            ## get cos sim matrix\n",
    "            path = '/data/dirksonar/TextFooler/TextFooler-master/TextFooler-master/cos_sim_counter_fitting.npy'\n",
    "            self.cos_sim = np.load (path)\n",
    "            \n",
    "            self.idx2word = {}\n",
    "            self.word2idx = {}\n",
    "\n",
    "            pathcf = '/data/dirksonar/TextFooler/TextFooler-master/TextFooler-master/counter-fitted-vectors.txt'\n",
    "\n",
    "            print(\"Building vocab...\")\n",
    "            with open(pathcf, 'r') as ifile:\n",
    "                for line in ifile:\n",
    "                    word = line.split()[0]\n",
    "                    if word not in self.idx2word:\n",
    "                        self.idx2word[len(self.idx2word)] = word\n",
    "                        self.word2idx[word] = len(self.idx2word) - 1\n",
    "    \n",
    "    def load_obj(self, name):\n",
    "        with open(name + '.pkl', 'rb') as f:\n",
    "            return pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    def save_obj(self, obj, name):\n",
    "        with open(name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "    def initialize_model(self,modelpath, labelfile):\n",
    "#         labellst2 = [i for j in labellst for i in j]\n",
    "#         self.labels = list(set(labellst2)) \n",
    "#         print(self.labels)\n",
    "        self.labels = get_labels(labelfile)\n",
    "#         self.labels = ['I-location', 'I-group', 'O', 'B-creative-work', 'I-product', 'B-corporation', 'I-corporation', 'B-product', 'I-creative-work', 'B-location', 'B-group', 'I-person', 'B-person']\n",
    "    \n",
    "        self.num_labels = len(self.labels)\n",
    "        # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "        self.pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "        self.max_seq_length = 128\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(modelpath, do_lower_case = False)\n",
    "        self.model = BertForTokenClassification.from_pretrained(modelpath)\n",
    "    \n",
    "    \n",
    "    def set_seed(self,num, n_gpu):\n",
    "#         random.seed(num)\n",
    "        np.random.seed(num)\n",
    "        torch.manual_seed(num)\n",
    "        if n_gpu > 0:\n",
    "                torch.cuda.manual_seed_all(num)\n",
    "                \n",
    "    def cosine_similarity(self, v1, v2):\n",
    "        mag1 = np.linalg.norm(v1)\n",
    "        mag2 = np.linalg.norm(v2)\n",
    "        if (not mag1) or (not mag2):\n",
    "            return 0\n",
    "        return np.dot(v1, v2) / (mag1 * mag2)\n",
    "\n",
    "    def test_similarity(self,text1, text2):\n",
    "        vecs = self.embed([text1, text2])['outputs']\n",
    "        v1 = vecs[0]\n",
    "        v2 = vecs[1]\n",
    "        return self.cosine_similarity(v1, v2)\n",
    "    \n",
    "    def get_stopwords(self):\n",
    "        '''\n",
    "        :return: a set of 266 stop words from nltk. eg. {'someone', 'anyhow', 'almost', 'none', 'mostly', 'around', 'being', 'fifteen', 'moreover', 'whoever', 'further', 'not', 'side', 'keep', 'does', 'regarding', 'until', 'across', 'during', 'nothing', 'of', 'we', 'eleven', 'say', 'between', 'upon', 'whole', 'in', 'nowhere', 'show', 'forty', 'hers', 'may', 'who', 'onto', 'amount', 'you', 'yours', 'his', 'than', 'it', 'last', 'up', 'ca', 'should', 'hereafter', 'others', 'would', 'an', 'all', 'if', 'otherwise', 'somehow', 'due', 'my', 'as', 'since', 'they', 'therein', 'together', 'hereupon', 'go', 'throughout', 'well', 'first', 'thence', 'yet', 'were', 'neither', 'too', 'whether', 'call', 'a', 'without', 'anyway', 'me', 'made', 'the', 'whom', 'but', 'and', 'nor', 'although', 'nine', 'whose', 'becomes', 'everywhere', 'front', 'thereby', 'both', 'will', 'move', 'every', 'whence', 'used', 'therefore', 'anyone', 'into', 'meanwhile', 'perhaps', 'became', 'same', 'something', 'very', 'where', 'besides', 'own', 'whereby', 'whither', 'quite', 'wherever', 'why', 'latter', 'down', 'she', 'sometimes', 'about', 'sometime', 'eight', 'ever', 'towards', 'however', 'noone', 'three', 'top', 'can', 'or', 'did', 'seemed', 'that', 'because', 'please', 'whereafter', 'mine', 'one', 'us', 'within', 'themselves', 'only', 'must', 'whereas', 'namely', 'really', 'yourselves', 'against', 'thus', 'thru', 'over', 'some', 'four', 'her', 'just', 'two', 'whenever', 'seeming', 'five', 'him', 'using', 'while', 'already', 'alone', 'been', 'done', 'is', 'our', 'rather', 'afterwards', 'for', 'back', 'third', 'himself', 'put', 'there', 'under', 'hereby', 'among', 'anywhere', 'at', 'twelve', 'was', 'more', 'doing', 'become', 'name', 'see', 'cannot', 'once', 'thereafter', 'ours', 'part', 'below', 'various', 'next', 'herein', 'also', 'above', 'beside', 'another', 'had', 'has', 'to', 'could', 'least', 'though', 'your', 'ten', 'many', 'other', 'from', 'get', 'which', 'with', 'latterly', 'now', 'never', 'most', 'so', 'yourself', 'amongst', 'whatever', 'whereupon', 'their', 'serious', 'make', 'seem', 'often', 'on', 'seems', 'any', 'hence', 'herself', 'myself', 'be', 'either', 'somewhere', 'before', 'twenty', 'here', 'beyond', 'this', 'else', 'nevertheless', 'its', 'he', 'except', 'when', 'again', 'thereupon', 'after', 'through', 'ourselves', 'along', 'former', 'give', 'enough', 'them', 'behind', 'itself', 'wherein', 'always', 'such', 'several', 'these', 'everyone', 'toward', 'have', 'nobody', 'elsewhere', 'empty', 'few', 'six', 'formerly', 'do', 'no', 'then', 'unless', 'what', 'how', 'even', 'i', 'indeed', 'still', 'might', 'off', 'those', 'via', 'fifty', 'each', 'out', 'less', 're', 'take', 'by', 'hundred', 'much', 'anything', 'becoming', 'am', 'everything', 'per', 'full', 'sixty', 'are', 'bottom', 'beforehand'}\n",
    "        '''\n",
    "        stop_words = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'ain', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'aren', \"aren't\", 'around', 'as', 'at', 'back', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'both',  'but', 'by', 'can', 'cannot', 'could', 'couldn', \"couldn't\", 'd', 'didn', \"didn't\", 'doesn', \"doesn't\", 'don', \"don't\", 'down', 'due', 'during', 'either', 'else', 'elsewhere', 'empty', 'enough', 'even', 'ever', 'everyone', 'everything', 'everywhere', 'except',  'first', 'for', 'former', 'formerly', 'from', 'hadn', \"hadn't\",  'hasn', \"hasn't\",  'haven', \"haven't\", 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'if', 'in', 'indeed', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'latter', 'latterly', 'least', 'll', 'may', 'me', 'meanwhile', 'mightn', \"mightn't\", 'mine', 'more', 'moreover', 'most', 'mostly',  'must', 'mustn', \"mustn't\", 'my', 'myself', 'namely', 'needn', \"needn't\", 'neither', 'never', 'nevertheless', 'next', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'o', 'of', 'off', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'per', 'please','s', 'same', 'shan', \"shan't\", 'she', \"she's\", \"should've\", 'shouldn', \"shouldn't\", 'somehow', 'something', 'sometime', 'somewhere', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they','this', 'those', 'through', 'throughout', 'thru', 'thus', 'to', 'too','toward', 'towards', 'under', 'unless', 'until', 'up', 'upon', 'used',  've', 'was', 'wasn', \"wasn't\", 'we',  'were', 'weren', \"weren't\", 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'with', 'within', 'without', 'won', \"won't\", 'would', 'wouldn', \"wouldn't\", 'y', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "        stop_words = set(stop_words)\n",
    "        return stop_words\n",
    "    \n",
    "    def pos_filter(self, ori_pos, new_pos_list):\n",
    "        same = [True if ori_pos == new_pos\n",
    "                else False\n",
    "                for new_pos in new_pos_list]\n",
    "        return same\n",
    "\n",
    "    def pick_most_similar_words_batch(self, src_words, sim_mat, idx2word, ret_count=10, threshold=0.5):\n",
    "        \"\"\"\n",
    "        embeddings is a matrix with (d, vocab_size)\n",
    "        \"\"\"\n",
    "        sim_order = np.argsort(-sim_mat[src_words, :])[:, 1:1 + ret_count]\n",
    "        sim_words, sim_values = [], []\n",
    "        for idx, src_word in enumerate(src_words):\n",
    "            sim_value = sim_mat[src_word][sim_order[idx]]\n",
    "            mask = sim_value >= threshold\n",
    "            sim_word, sim_value = sim_order[idx][mask], sim_value[mask]\n",
    "            sim_word = [idx2word[id] for id in sim_word]\n",
    "            sim_words.append(sim_word)\n",
    "            sim_values.append(sim_value)\n",
    "        return sim_words, sim_values\n",
    "\n",
    "    def prepare_data_for_eval(self, examples): \n",
    "        features = convert_examples_to_features(examples, self.labels, self.max_seq_length, self.tokenizer,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=self.tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=self.tokenizer.sep_token,\n",
    "                                                    pad_token=self.tokenizer.convert_tokens_to_ids([self.tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id= 0,\n",
    "                                                    pad_token_label_id=self.pad_token_label_id\n",
    "                                                    )\n",
    "        \n",
    "        # Convert to Tensors and build dataset\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "        \n",
    "        dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "        return dataset\n",
    "\n",
    "    def read_examples_from_list(self, data, mode): ## this does not incorporate labels but just adds 'O's\n",
    "        guid_index = 0\n",
    "        examples = []\n",
    "        for s in data: #data is a list\n",
    "            words = []\n",
    "            labels = []\n",
    "            guid_index += 1\n",
    "            for num, w in enumerate(s): \n",
    "                words.append(w)\n",
    "                labels.append(\"O\")\n",
    "\n",
    "#             print(len(words))\n",
    "#             print(words)\n",
    "\n",
    "            examples.append(InputExample(guid=\"%s-%d\".format(mode, guid_index),\n",
    "                                            words=words,\n",
    "                                             labels=labels))\n",
    "        return examples\n",
    "\n",
    "\n",
    "    def read_examples_from_lists_wlables(self, data, labels, mode): ## this does not incorporate labels but just adds 'O's\n",
    "        guid_index = 0\n",
    "        examples = []\n",
    "        for s, l in zip(data, labels): #data is a list\n",
    "            words = []\n",
    "            labels = []\n",
    "            guid_index += 1\n",
    "            for num, w in enumerate(s): \n",
    "                words.append(w)\n",
    "                labels.append(l[num])\n",
    "\n",
    "            examples.append(InputExample(guid=\"%s-%d\".format(mode, guid_index),\n",
    "                                            words=words,\n",
    "                                             labels=labels))\n",
    "        return examples\n",
    "\n",
    "    def evaluate(self, eval_dataset, model, tokenizer, labels, pad_token_label_id, mode = 'test', prefix=\"\"):\n",
    "        eval_sampler = SequentialSampler(eval_dataset) \n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=32)\n",
    "\n",
    "        # Eval!\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        model.eval()\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "    #         batch = tuple(t.to(args.device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {\"input_ids\": batch[0],\n",
    "                          \"attention_mask\": batch[1],\n",
    "                          \"token_type_ids\": batch[2],\n",
    "                          # XLM and RoBERTa don\"t use segment_ids\n",
    "                          \"labels\": batch[3]}\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "    #             if args.n_gpu > 1:\n",
    "    #                 tmp_eval_loss = tmp_eval_loss.mean()  # mean() to average on multi-gpu parallel evaluating\n",
    "\n",
    "                eval_loss += tmp_eval_loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        probs = preds\n",
    "        preds = np.argmax(preds, axis=2)\n",
    "\n",
    "        label_map = {i: label for i, label in enumerate(labels)}\n",
    "        \n",
    "        out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        old_preds_list = preds_list\n",
    "\n",
    "        for i in range(out_label_ids.shape[0]):\n",
    "            for j in range(out_label_ids.shape[1]):\n",
    "                if out_label_ids[i, j] != pad_token_label_id:\n",
    "                    out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "                    preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "        results = {\n",
    "            \"loss\": eval_loss,\n",
    "            \"precision\": precision_score(out_label_list, preds_list),\n",
    "            \"recall\": recall_score(out_label_list, preds_list),\n",
    "            \"f1\": f1_score(out_label_list, preds_list)\n",
    "        }\n",
    "\n",
    "    #     logger.info(\"***** Eval results %s *****\", prefix)\n",
    "    #     for key in sorted(results.keys()):\n",
    "    #         logger.info(\"  %s = %s\", key, str(results[key]))\n",
    "\n",
    "        return results, preds_list, probs, preds, old_preds_list, out_label_list, label_map\n",
    "    \n",
    "\n",
    "    def get_entities (self, pred_tags): \n",
    "        ent_ids = []\n",
    "        ent_tags = []\n",
    "        for num, i in enumerate (pred_tags):\n",
    "            temp = []\n",
    "            temp2 = []\n",
    "            if i.startswith('B-'):\n",
    "                temp.append(num)\n",
    "                temp2.append(i)\n",
    "                for x in range(1, 20): \n",
    "                    try: \n",
    "\n",
    "                        if pred_tags[num+x].startswith ('I-'): \n",
    "                            temp.append(num+x)\n",
    "                            temp2.append(pred_tags[num+x])\n",
    "                        else: \n",
    "                            break \n",
    "                    except IndexError: \n",
    "                        break\n",
    "                ent_ids.append(temp)\n",
    "                ent_tags.append(temp2)\n",
    "            else: \n",
    "                pass\n",
    "        return ent_ids, ent_tags\n",
    "    \n",
    "    def calcwordscore(self, orig_label, orig_prob, leave_1_probs, nw_labels, ix2): \n",
    "        w =  (orig_prob.max() - leave_1_probs[ix2][orig_prob.argmax()] + (int(nw_labels[ix2] != orig_label) * (\n",
    "                        leave_1_probs[ix2].max() - orig_prob[leave_1_probs[ix2].argmax()])))\n",
    "#         if nw_labels[ix2] != orig_label: \n",
    "#             print(nw_labels[ix2])\n",
    "        return w\n",
    "\n",
    "    def calcwordscore_Itag(self, orig_label, orig_prob, leave_1_probs, nw_labels, ix2):\n",
    "        w =  (orig_prob.max() - leave_1_probs[ix2][orig_prob.argmax()] + (int(nw_labels[ix2][2:] != orig_label[2:]) * (\n",
    "                        leave_1_probs[ix2].max() - orig_prob[leave_1_probs[ix2].argmax()])))\n",
    "        return w\n",
    "    \n",
    "    def calculate_importance_scores (self, ent, preds_listnw, probsnw, leave_1_texts, sent_allowed, allowed_ids): \n",
    "        mean_import_scores = []\n",
    "        all_import_scores = []\n",
    "\n",
    "        for ix in ent: ##for each word in entity we calculate importance of words. ix is hte index of hte word in the sentence\n",
    "            orig_label = preds_listnw[0][ix]\n",
    "            orig_prob = probsnw[0][ix+1]\n",
    "            leave_1_probs= []\n",
    "            nw_labels =[]\n",
    "            for i in range(1, len(leave_1_texts)): \n",
    "                [leave_1_probs.append(probsnw[i][ix+1])]##new probabilities of this word ##need to add 1 to compensate for padded token\n",
    "                try: \n",
    "                    [nw_labels.append (preds_listnw[i][ix])] ##new lables of this word\n",
    "                except IndexError:\n",
    "                    return 0\n",
    "            import_scores = []\n",
    "            nw_leave_1_texts = leave_1_texts[1:]\n",
    "            for ix2, word in enumerate(nw_leave_1_texts):   \n",
    "                if orig_label.startswith('I'): \n",
    "                    wordscore = self.calcwordscore_Itag(orig_label, orig_prob, leave_1_probs, nw_labels, ix2)\n",
    "                else: \n",
    "                    wordscore = self.calcwordscore(orig_label, orig_prob, leave_1_probs, nw_labels, ix2)\n",
    "                ## the last part says what the probability of the new label (if there is one) without hte word minus that same prob WITH the word\n",
    "                import_scores.append(wordscore)\n",
    "            all_import_scores.append(import_scores) ##list of lists\n",
    "        sum_import_scores = np.sum(all_import_scores, axis =0)\n",
    "        import_score_threshold=-1\n",
    "        words_perturb = []\n",
    "        for idx, score in sorted(enumerate(sum_import_scores), key=lambda x: x[1], reverse=True):\n",
    "\n",
    "            if score > import_score_threshold and sent_allowed[idx] not in self.stop_words_set:\n",
    "                words_perturb.append((allowed_ids[idx], sent_allowed[idx]))\n",
    "\n",
    "#         print(words_perturb)\n",
    "        return words_perturb\n",
    "\n",
    "    def random_ranking(self, ent, leave_1_texts, sent_allowed, allowed_ids): \n",
    "        words_perturb = []\n",
    "        nw_leave_1_texts = leave_1_texts[1:]\n",
    "        for idx, word in enumerate(nw_leave_1_texts): \n",
    "            if sent_allowed[idx] not in self.stop_words_set:\n",
    "                words_perturb.append((allowed_ids[idx], sent_allowed[idx]))\n",
    "        random.seed(1)\n",
    "        random.shuffle(words_perturb)\n",
    "#         print(words_perturb)\n",
    "        return words_perturb  \n",
    "    \n",
    "    def get_adversarial_examples_per_sent(self, sent, origlbl, predlbl, ent_tags, ent_ids, random_attack = False, sim_synonyms=0.5, sim_score_threshold=0.8, import_score_threshold = -1, sim_predictor = None, synonym_num=50,batch_size=32):   \n",
    "        if sim_predictor == None: \n",
    "            sim_predictor == self.embed\n",
    "        \n",
    "        out_texts = []\n",
    "#         ent_ids, ent_tags = get_entities(origlbl)\n",
    "        taboo_ids = [i for j in ent_ids for i in j]\n",
    "        len_text = len(sent)\n",
    "        sent_allowed = [i for num, i in enumerate(sent) if num not in taboo_ids]\n",
    "        allowed_ids = [num for num, i in enumerate(sent) if num not in taboo_ids]\n",
    "#         print(sent_allowed)\n",
    "        pos_ls = criteria.get_pos(sent)\n",
    "\n",
    "        for entnum, ent in enumerate(ent_ids): ##for each entity\n",
    "            success= 0\n",
    "#             print(ent)\n",
    "#             print(sent)\n",
    "#             print(origlbl)\n",
    "            \n",
    "            \n",
    "            leave_1_texts = []\n",
    "            leave_1_texts.append(sent)\n",
    "            for idword, word in enumerate(sent): \n",
    "                if idword not in taboo_ids:\n",
    "    #                 print(text_ls)\n",
    "                    a_text = sent[:idword] + ['<oov>'] + sent[min(idword+1, len_text):] #until the end of sentence or id + 1\n",
    "                    leave_1_texts.append(a_text)\n",
    "\n",
    "            ##need to prepare for eval \n",
    "            examples = self.read_examples_from_list(leave_1_texts, 'test')\n",
    "            dataset = self.prepare_data_for_eval(examples)\n",
    "\n",
    "            resultsnw, preds_listnw, probsnw, predsnw, old_preds_listnw, true_labelsnw, label_map2= self.evaluate(dataset, self.model, self.tokenizer, self.labels, self.pad_token_label_id)\n",
    "            #this gives predictions for all words but we need to pick out hte relevant ones\n",
    "#             print(preds_listnw[0])\n",
    "#             print(preds_listnw[0] == predlbl)\n",
    "            mean_import_scores = []\n",
    "            all_import_scores = []\n",
    "            \n",
    "            if random_attack == False:\n",
    "                words_perturb = self.calculate_importance_scores (ent, preds_listnw, probsnw, leave_1_texts, sent_allowed, allowed_ids)\n",
    "            else: \n",
    "                words_perturb = self.random_ranking(ent, leave_1_texts, sent_allowed, allowed_ids)\n",
    "#             print(words_perturb)\n",
    "            \n",
    "            if words_perturb == 0: ##there are none\n",
    "                out = 'This sentence was a problem'\n",
    "                out_texts.append(out)\n",
    "            else:\n",
    "                # find synonyms\n",
    "                words_perturb_idx = [self.word2idx[word] for idx, word in words_perturb if word in self.word2idx]\n",
    "                synonym_words, _ = self.pick_most_similar_words_batch(words_perturb_idx, self.cos_sim, self.idx2word, synonym_num, sim_synonyms)\n",
    "                synonyms_all = []\n",
    "                for idx, word in words_perturb:\n",
    "                    if word in self.word2idx:\n",
    "                        synonyms = synonym_words.pop(0)\n",
    "                        if synonyms:\n",
    "                            synonyms_all.append((idx, synonyms))\n",
    "\n",
    "                # start replacing and attacking until label changes\n",
    "                text_prime = sent[:]\n",
    "                text_cache = text_prime[:]\n",
    "                num_changed = 0\n",
    "                unchanged_ent = ent\n",
    "    #             print(len(synonyms_all))\n",
    "    \n",
    "                if len(synonyms_all) == 0: \n",
    "                    out2 = 'No synonyms'\n",
    "                    out_texts.append(out2)\n",
    "                    break\n",
    "                    \n",
    "                for idx, synonyms in synonyms_all:\n",
    "    #                 print(len(synonyms))\n",
    "    #                 finalsim = self.test_similarity(' '.join(text_cache),' '.join(text_prime))\n",
    "    #                 print(finalsim)\n",
    "                    new_texts = [text_prime[:idx] + [synonym] + text_prime[min(idx + 1, len_text):] for synonym in synonyms]\n",
    "    #                 print(len(new_texts))\n",
    "                    new_texts.append(sent)\n",
    "                    examples = self.read_examples_from_list(new_texts, 'test')# \n",
    "    #                 print(new_texts)\n",
    "                    dataset = self.prepare_data_for_eval(examples)\n",
    "\n",
    "                    results2, preds_list2, probs2, preds2, old_preds_list2, true_labels2, label_map2nw= self.evaluate(dataset,self.model, self.tokenizer, self.labels, self.pad_token_label_id)           \n",
    "\n",
    "                    # compute semantic similarity\n",
    "                    semantic_sims = []\n",
    "\n",
    "                    for i in new_texts: \n",
    "    #                     print(i)\n",
    "    #                     print(text_cache)\n",
    "                        sim = self.test_similarity(' '.join(text_cache),' '.join(i))\n",
    "    #                     print(sim)\n",
    "                        semantic_sims.append(sim)\n",
    "    #                 print(semantic_sims)\n",
    "\n",
    "                    if len(ent) == 1: # it is a single word entity\n",
    "    #                     print('Branch of the single word')\n",
    "                        rel_probs=[]\n",
    "                        new_probs_mask=[]\n",
    "                        ix = ent[0]\n",
    "                        correct = probs2[-1][ix+1].argmax()\n",
    "                        for i in range(0, (len(new_texts)-1)): \n",
    "                            [rel_probs.append(probs2[i][ix+1])]\n",
    "                        new_texts2 = new_texts[:-1]\n",
    "                        for ix2, t in enumerate(new_texts2):\n",
    "                            r = rel_probs[ix2]\n",
    "                            new_probs_mask.append(correct != r.argmax())    \n",
    "                        new_probs_mask2 = np.array(new_probs_mask)\n",
    "\n",
    "                        semsims = semantic_sims[:-1]\n",
    "                        semantic_sims2 = np.array(semsims)\n",
    "\n",
    "                        synonyms_pos_ls = [criteria.get_pos(new_text[max(idx - 4, 0):idx + 5])[min(4, idx)]\n",
    "                                                           if len(new_text) > 10 else criteria.get_pos(new_text)[idx] for new_text in new_texts2]\n",
    "\n",
    "                        pos_ls = criteria.get_pos(sent)\n",
    "\n",
    "                        new_probs_mask2 *= (semantic_sims2 >= sim_score_threshold)\n",
    "    #                     print(new_probs_mask2)\n",
    "                        pos_mask = np.array(self.pos_filter(pos_ls[idx], synonyms_pos_ls))\n",
    "                        new_probs_mask2 *= pos_mask\n",
    "\n",
    "                        if np.sum(new_probs_mask2) > 0: ##there is an instance that changes the label\n",
    "                            z = (new_probs_mask2 * semantic_sims2).argmax()\n",
    "                            if semantic_sims2[z] < sim_score_threshold:\n",
    "    #                             print('This is below the threshold')\n",
    "                                break\n",
    "                            text_prime[idx] = synonyms[z]\n",
    "                            num_changed += 1\n",
    "    #                         print(text_prime)\n",
    "    #                         print('We will stop')\n",
    "                            success = 1\n",
    "                            success_p = success/1\n",
    "                            break\n",
    "                        else: ##no label change at all - But if not, then we select the word with the least confidence score of label y as the best replacement word for wi\n",
    "                            nw_rel_probs = [i[correct] for i in rel_probs]\n",
    "\n",
    "                            nw_rel_probs2 = nw_rel_probs + (semantic_sims2 < sim_score_threshold) + (1 - pos_mask)\n",
    "\n",
    "                            new_label_prob_min = nw_rel_probs2.min()\n",
    "                            new_label_prob_argmin = nw_rel_probs2.argmin()\n",
    "                            if semantic_sims2[new_label_prob_argmin] < sim_score_threshold:\n",
    "    #                             print('This is below the threshold')\n",
    "                                break\n",
    "\n",
    "                            orig_prob = probs2[-1][ix+1].max()\n",
    "                            if new_label_prob_min < orig_prob:\n",
    "                                text_prime[idx] = synonyms[new_label_prob_argmin]\n",
    "    #                             print(text_prime)\n",
    "    #                             print(synonyms[new_label_prob_argmin])\n",
    "                                num_changed += 1\n",
    "    #                             print('We will go on')\n",
    "    #                         else:\n",
    "    #                             print('Probs were not high enough')\n",
    "\n",
    "\n",
    "                    else: #it is a multiword entity   -- unchanged ent is the part of hte entity that has not been changed.                 \n",
    "    #                     print('Branch of the multiword')\n",
    "                        correctlbl = []\n",
    "                        correctlblname = []\n",
    "    #                     print('the unchanged ents are now:')\n",
    "    #                     print(unchanged_ent)\n",
    "                        for ix in unchanged_ent: \n",
    "                            correctlbl.append(probs2[-1][ix+1].argmax())\n",
    "                            correctlblname.append(preds_list2[-1][ix])\n",
    "    #                     print(correctlblname)\n",
    "\n",
    "                        new_probs_mask_temp=[]\n",
    "                        all_rel_probs = []\n",
    "                        for number, ix in enumerate(unchanged_ent):\n",
    "                            rel_probs=[]\n",
    "                            new_probs_mask=[]\n",
    "                            for i in range(0, (len(new_texts)-1)): \n",
    "                                [rel_probs.append(probs2[i][ix+1])]\n",
    "                            all_rel_probs.append(rel_probs)\n",
    "                            correct = probs2[-1][ix+1].argmax()\n",
    "                            new_texts2 = new_texts[:-1]\n",
    "                            c = correctlblname[number]\n",
    "                            if c.startswith('I'): \n",
    "    #                             print(c)\n",
    "                                for ix2, t in enumerate(new_texts2): \n",
    "                                    pl = preds_list2[ix2][ix] ##predicted label\n",
    "                                    if pl[2:] == c[2:]: ##if the predicted label is either the B or I version of the originla label = no label change \n",
    "                                        new_probs_mask.append(False)\n",
    "                                    else:\n",
    "                                        new_probs_mask.append(True)                            \n",
    "                            else: \n",
    "                                for ix2, t in enumerate(new_texts2): \n",
    "                                    r = rel_probs[ix2]\n",
    "                                    new_probs_mask.append(correct != r.argmax()) ## true is label has been changed.\n",
    "\n",
    "                            new_probs_mask_temp.append(np.array(new_probs_mask))\n",
    "\n",
    "                        m = np.matrix(new_probs_mask_temp)\n",
    "\n",
    "\n",
    "                        unchanged_lbls = [] ## contains hte indexes of hte words changed in the entity- not the ix in the sentence\n",
    "    #                     print(len(new_texts))\n",
    "\n",
    "                        if len(new_texts) > 0: ## there are some synonyms \n",
    "    #                         print(len(new_texts))\n",
    "    #                         print(m)\n",
    "                            for i in range(0, (len(new_texts)-1)):\n",
    "    #                             print(i)\n",
    "                                try: \n",
    "                                    z = np.argwhere(m[:,i] == 0)[:,0]\n",
    "                                    unchanged_lbls.append(z.flatten().tolist()) \n",
    "                                except IndexError: \n",
    "                                    print(m)\n",
    "                                    z = []\n",
    "                                    unchanged_lbls.append(z)\n",
    "\n",
    "    #                         print('the unchanged labels for each synonym are:') \n",
    "    #                         print(unchanged_lbls)\n",
    "\n",
    "                        new_probs_mask2 = np.sum(new_probs_mask_temp,axis = 0) ##true if any of the entity words have changed label with higher number for more label changes. \n",
    "\n",
    "                        semsims = semantic_sims[:-1]\n",
    "                        semantic_sims2 = np.array(semsims)\n",
    "                        synonyms_pos_ls = [criteria.get_pos(new_text[max(idx - 4, 0):idx + 5])[min(4, idx)]\n",
    "                                                           if len(new_text) > 10 else criteria.get_pos(new_text)[idx] for new_text in new_texts2]\n",
    "                        pos_ls = criteria.get_pos(sent)\n",
    "                        pos_mask = np.array(self.pos_filter(pos_ls[idx], synonyms_pos_ls))\n",
    "\n",
    "                        new_probs_mask2 *= (semantic_sims2 >= sim_score_threshold)\n",
    "                        new_probs_mask2 *= pos_mask\n",
    "\n",
    "                        ## are there any that change all labels? MAKE A MASK\n",
    "                        entmax = len(unchanged_ent)\n",
    "    #                     w = np.argwhere(new_probs_mask2 == entmax)\n",
    "    #                     lstw = w.flatten().tolist()\n",
    "    #                     print('entmax: ') \n",
    "    #                     print(entmax)\n",
    "                        new_probs_mask_all = [1 if x == entmax else 0 for x in new_probs_mask2]\n",
    "    #                     print(new_probs_mask_all)\n",
    "    #                     print(new_probs_mask2)\n",
    "    #                     print(np.sum(new_probs_mask2))\n",
    "\n",
    "                        if np.sum(new_probs_mask_all) > 0: ## there are synonyms that can change all the labels! BEST SCENARIO\n",
    "                            z= (new_probs_mask_all * semantic_sims2).argmax()\n",
    "                            if semantic_sims2[z] < sim_score_threshold:\n",
    "    #                             print('This is below the threshold')\n",
    "                                break\n",
    "                            text_prime[idx] = synonyms[z]\n",
    "                            num_changed += 1\n",
    "    #                         print(text_prime)                          \n",
    "    #                         print('We will stop')\n",
    "                            success = 1\n",
    "                            success_p = success/1\n",
    "                            break\n",
    "\n",
    "                        elif np.sum(new_probs_mask2) > 0: ##there is an instance that changes the label\n",
    "                            winners = np.argwhere(new_probs_mask2 == np.amax(new_probs_mask2))\n",
    "    #                         print('some have changed')\n",
    "                            lstwinners = winners.flatten().tolist() ##the ix of ones that make the highest number of words change but also conform to filters\n",
    "\n",
    "                            winner_probs = []\n",
    "\n",
    "                            for a in lstwinners:\n",
    "                                u = unchanged_lbls[a]\n",
    "\n",
    "                                ##retrieve correct prob of unchanged labels to compare\n",
    "                                rp = [i for num, i in enumerate(all_rel_probs) if num in u] ##ones for right entities\n",
    "\n",
    "                                rp2 = [i[a] for i in rp] #get the ones for this synonym\n",
    "\n",
    "                                cor = [i for num, i in enumerate(correctlbl) if num in u] ##ix of correct labels for relevant entities\n",
    "\n",
    "                                rp_out = []\n",
    "                                for a,b in zip(cor, rp2):\n",
    "                                    rp_out.append(np.array(b[a]))\n",
    "\n",
    "                                rp_out2 = np.array(rp_out)\n",
    "                                rp_sum = np.sum(rp_out2,axis =0) #summed confidence of all the relevant words in the entity\n",
    "                                winner_probs.append(rp_sum)\n",
    "\n",
    "                            ##choose the lowest winner prob - lowest for other entities\n",
    "                            winner_probs2 = np.array(winner_probs)\n",
    "\n",
    "                            new_label_prob_min = winner_probs2.min()\n",
    "                            new_label_prob_argmin = winner_probs2.argmin()\n",
    "\n",
    "                            winning_ix = lstwinners[new_label_prob_argmin]\n",
    "\n",
    "                            ##change the unchanged ent for next iteration\n",
    "                            u = unchanged_lbls[winning_ix]\n",
    "                            nw_unchanged_ent = [i for num,i in enumerate(unchanged_ent) if num in u] ##actual indexes in sentences\n",
    "                            unchanged_ent = nw_unchanged_ent\n",
    "    #                         print(unchanged_ent)\n",
    "\n",
    "                            if semantic_sims2[winning_ix] < sim_score_threshold:\n",
    "                                print('This is below the threshold')\n",
    "                                break\n",
    "\n",
    "    #                         for ix in unchanged_ent: \n",
    "    #                             o = [probs2[-1][ix+1].max()]\n",
    "    #                             o2 = np.sum(np.array(o)) \n",
    "\n",
    "    #                         if new_label_prob_min < o2:\n",
    "                            text_prime[idx] = synonyms[winning_ix]\n",
    "    #                             print(text_prime)\n",
    "                            num_changed += 1\n",
    "    #                             print('We have changed some but will continue')\n",
    "                            success += 1\n",
    "                            success_p = success/len(ent)\n",
    "                            print(success_p)\n",
    "                            text_cache2 = text_prime\n",
    "                            if success_p == 1:\n",
    "                                break\n",
    "\n",
    "\n",
    "                        else: ##no label change at all - But if not, then we select the word with the least confidence score of label y as the best replacement word for wi\n",
    "    #                         print('no label change')\n",
    "                            rp_out = []\n",
    "                            for a,b in zip(correctlbl, all_rel_probs): #correct is the correct labels and all rel probs is the probabilities for hte wrods in the entities\n",
    "                                rp = [x[a] for x in b] \n",
    "                                rp_out.append(np.array(rp))\n",
    "                            rp_sum = np.sum(rp_out,axis =0) #summed confidence of all the words in the entity\n",
    "                            nw_rel_probs2 = rp_sum + (semantic_sims2 < sim_score_threshold) + (1 - pos_mask)\n",
    "\n",
    "                            new_label_prob_min = nw_rel_probs2.min()\n",
    "                            new_label_prob_argmin = nw_rel_probs2.argmin()\n",
    "    #                         print(semantic_sims2[new_label_prob_argmin])\n",
    "    #                         print(semantic_sims2.max())\n",
    "\n",
    "                            if semantic_sims2[new_label_prob_argmin] < sim_score_threshold:\n",
    "    #                             print('This is below the threshold')\n",
    "                                break\n",
    "                            ##get orig prob \n",
    "                            for ix in unchanged_ent: \n",
    "                                o = [probs2[-1][ix+1].max()]\n",
    "                                o2 = np.sum(np.array(o)) \n",
    "\n",
    "                            if new_label_prob_min < o2:\n",
    "                                text_prime[idx] = synonyms[new_label_prob_argmin]\n",
    "                                num_changed += 1\n",
    "\n",
    "\n",
    "                ##calculate semantic sim\n",
    "\n",
    "                try: \n",
    "                    if 0<success_p<1: \n",
    "    #                     print('We are reverting!')\n",
    "    #                     print(text_prime)\n",
    "                        text_prime= text_cache2\n",
    "    #                     print(text_cache2)\n",
    "                except UnboundLocalError: \n",
    "                    pass\n",
    "\n",
    "                finalsim = self.test_similarity(' '.join(text_cache),' '.join(text_prime))\n",
    "\n",
    "                max_possible = len(synonyms_all)\n",
    "                if success == 0: \n",
    "                    success_p = 0\n",
    "                out_texts.append(tuple([text_prime, num_changed, max_possible, success_p, finalsim]))\n",
    "\n",
    "        return out_texts\n",
    "    \n",
    "    def retrieve_entities(self,devdata, traindata,testdata): \n",
    "        ##first make a list of entities possible\n",
    "        alldata = pd.concat([devdata, traindata,testdata])\n",
    "        words = list(alldata['words'])\n",
    "        tags = list(alldata['ner'])\n",
    "\n",
    "        flattags = [i for j in tags for i in j]\n",
    "        flattags2 = [i[2:] for i in flattags]\n",
    "        tagset = set(flattags2)\n",
    "        taglist = [i for i in list(tagset) if i != '' and i != 'MISC']\n",
    "        print(taglist)\n",
    "        allent = []\n",
    "        ent_ids = []\n",
    "        ent_tags = []\n",
    "        for i in tags: \n",
    "            e1, e2 = self.get_entities(i)\n",
    "            ent_ids.append(e1)\n",
    "            ent_tags.append(e2)\n",
    "\n",
    "        for i in taglist: ##for each entity \n",
    "            temp = []\n",
    "    #         print(i)\n",
    "            for a,b,c,d in zip(tags, words, ent_ids, ent_tags):\n",
    "                for num, t in enumerate(d): \n",
    "                    if t[0][2:] == i: ##is it hte correct entity\n",
    "                        l = []\n",
    "                        ix = c[num] ##get the ids\n",
    "                        [l.append(b[j]) for j in ix]\n",
    "                        temp.append(l)\n",
    "            allent.append(temp)\n",
    "\n",
    "        return taglist, allent\n",
    "    \n",
    "#     def test_get_adversarial_sent_entities (self, sent, origlbl, predlbl, ent_tags, ent_ids, taglst, allent, num_sample=50, sim_score_threshold=0.8, sim_predictor=None, batch_size=32): \n",
    "#         if sim_predictor == None: \n",
    "#             sim_predictor == self.embed\n",
    "#         out_texts = []\n",
    "# #         ent_idsold, ent_tagsold = get_entities(origlbl)\n",
    "# #         random.seed(1)\n",
    "#         len_text= len(sent)\n",
    "# #         print(ent_ids)\n",
    "#         for entnum, ent in enumerate(ent_ids):\n",
    "# #             print(ent)\n",
    "#             e = ent_tags[entnum]\n",
    "#             e1 = e[0][2:]\n",
    "# #             print(e1)\n",
    "#             try: \n",
    "#                 corix = taglst.index(e1)\n",
    "#                 correct_entlst = allent[corix]\n",
    "            \n",
    "#                 bcor = 'B-' + e1\n",
    "#                 icor = 'I-' + e1\n",
    "# #                 print(bcor)\n",
    "    \n",
    "#                 start = ent[0]\n",
    "#                 end = ent[-1]\n",
    "#                 idx = start\n",
    "\n",
    "#                 sam = random.sample(correct_entlst, num_sample)\n",
    "#                 print(sam)\n",
    "#             except ValueError: \n",
    "#                 pass\n",
    "    \n",
    "    def get_adversarial_sent_entities (self, sent, origlbl, predlbl, ent_tags, ent_ids, taglst, allent, num_sample=50, sim_score_threshold=0.8, sim_predictor=None, batch_size=32): \n",
    "        if sim_predictor == None: \n",
    "            sim_predictor == self.embed\n",
    "        out_texts = []\n",
    "#         ent_idsold, ent_tagsold = get_entities(origlbl)\n",
    "#         random.seed(1)\n",
    "        len_text= len(sent)\n",
    "#         print(ent_ids)\n",
    "        for entnum, ent in enumerate(ent_ids):\n",
    "#             print(ent)\n",
    "            e = ent_tags[entnum]\n",
    "            e1 = e[0][2:]\n",
    "#             print(e1)\n",
    "            try: \n",
    "                corix = taglst.index(e1)\n",
    "                correct_entlst = allent[corix]\n",
    "            \n",
    "                bcor = 'B-' + e1\n",
    "                icor = 'I-' + e1\n",
    "#                 print(bcor)\n",
    "    \n",
    "                start = ent[0]\n",
    "                end = ent[-1]\n",
    "                idx = start\n",
    "\n",
    "                sam = random.sample(correct_entlst, num_sample)\n",
    "                \n",
    "                comparewith = []\n",
    "                entidx = []\n",
    "                for syn in sam:\n",
    "                    cw = [bcor]\n",
    "                    if len(syn) > 1:\n",
    "                        [cw.append(icor) for i in range(1, len(syn))]\n",
    "                    comparewith.append(cw)\n",
    "                    ei = [ent[0]]\n",
    "                    if len(syn) > 1: \n",
    "                        [ei.append(ent[0] + i) for i in range(1, len(syn))]\n",
    "                    entidx.append(ei)\n",
    "#                 print(sam)\n",
    "                \n",
    "                text_prime = sent[:]\n",
    "                text_cache = text_prime[:]\n",
    "    #             print(sam)\n",
    "\n",
    "                new_texts = [text_prime[:start] + syn + text_prime[end+1:] for syn in sam]\n",
    "#                 print(new_texts)\n",
    "                \n",
    "                examples = self.read_examples_from_list(new_texts, 'test')# \n",
    "#                 print(new_texts)\n",
    "                dataset = self.prepare_data_for_eval(examples)\n",
    "\n",
    "                results2, preds_list2, probs2, preds2, old_preds_list2, true_labels2, label_map2nw= self.evaluate(dataset,self.model, self.tokenizer, self.labels, self.pad_token_label_id)           \n",
    "                    \n",
    "                # compute semantic similarity\n",
    "                semantic_sims = []\n",
    "                for i in new_texts: \n",
    "                    sim = self.test_similarity(' '.join(text_cache),' '.join(i))\n",
    "                    semantic_sims.append(sim)\n",
    "                new_probs_mask = []   \n",
    "                ##make a mask of if anyone managed\n",
    "                              \n",
    "                for a, b, c  in zip(comparewith, entidx, preds_list2):\n",
    "                    temp = []\n",
    "                    try: \n",
    "                        z = [c[i] for i in b] # the prediction\n",
    "                    except IndexError: \n",
    "                        print(comparewith)\n",
    "                        print(entidx)\n",
    "                        print(preds_list2)\n",
    "                        break\n",
    "                        \n",
    "                    for num, j in enumerate(z): ## j is hte predicted label and a is the GOOD label\n",
    "                        if j == a[num]: ##if the label did not change \n",
    "                            temp.append(0) \n",
    "                        if a[num] == icor and j == bcor: ##if the old lable was I and the new one is B\n",
    "                            temp.append(0)\n",
    "                        else: \n",
    "                            temp.append(1) ## this word did change\n",
    "\n",
    "                        t = np.sum(temp)/len(temp)\n",
    "                    new_probs_mask.append(t) ##relative amount of entity that was changed.\n",
    "\n",
    "                new_probs_mask2 = np.array(new_probs_mask)\n",
    "                semantic_sims2 = np.array(semantic_sims)\n",
    "                #mask if similarity is too low \n",
    "                new_probs_mask2 *= (semantic_sims2 >= sim_score_threshold)\n",
    "\n",
    "                ##did anyone manage? if yes output this.\n",
    "                if np.sum(new_probs_mask2) > 0: ##there is an instance that changes at least a part of a label\n",
    "                    success = np.amax(new_probs_mask2)\n",
    "\n",
    "                    new_probs_mask3 = [1 if x == success else 0 for x in new_probs_mask2]\n",
    "\n",
    "                    chosen = sam[(new_probs_mask3 * semantic_sims2).argmax()] \n",
    "#                     print(chosen)\n",
    "                    text_done = text_prime[:start] + chosen + text_prime[end+1:]\n",
    "                    success = 1\n",
    "#                     print(text_done)\n",
    "#                     print(text_cache)\n",
    "                    finalsim = self.test_similarity(' '.join(text_cache),' '.join(text_done))\n",
    "                    out_texts.append(tuple([text_done, success, finalsim]))\n",
    "\n",
    "                else: \n",
    "                    success = 0  ##if not, output this.\n",
    "                    chosen = random.choice(sam)\n",
    "                    text_done = text_prime[:start] + chosen + text_prime[end+1:]\n",
    "                    finalsim = self.test_similarity(' '.join(text_cache),' '.join(text_done))\n",
    "                    out_texts.append(tuple([text_done, success, finalsim]))\n",
    "            except ValueError:#happens when a MISC value occurs\n",
    "#                 print('the issue is this')\n",
    "#                 out_texts.append('There is a ValueError here')\n",
    "                pass\n",
    "        return out_texts   \n",
    "    \n",
    "    def first_prediction(self, sents, true_labels): \n",
    "        examples = self.read_examples_from_lists_wlables(sents, true_labels, 'test')\n",
    "        dataset = self.prepare_data_for_eval(examples)\n",
    "        results, preds_list, probs, preds, old_preds_list, true_labelsx, label_map= self.evaluate(dataset, self.model, self.tokenizer, self.labels, self.pad_token_label_id) \n",
    "        return results, preds_list, probs, preds, old_preds_list, true_labelsx, label_map\n",
    "    \n",
    "    \n",
    "    def identify_unfit_sents (self, true_labels, sents): \n",
    "        only_ent = []\n",
    "        no_ent = []\n",
    "        pat = '[A-Za-z]+'\n",
    "        for num, origlbl in enumerate(true_labels): \n",
    "            ent_ids, ent_tags = self.get_entities(origlbl)\n",
    "            taboo_ids = [i for j in ent_ids for i in j]\n",
    "            sent = sents[num]\n",
    "            len_text = len(sent)\n",
    "            nw_txt = [i for num,i in enumerate(sent) if num not in taboo_ids]\n",
    "            nw_txt2 = [i.lower() for i in nw_txt]\n",
    "            filt_txt= [i for i in nw_txt2 if i not in self.stop_words_set]\n",
    "            filt_txt2 = [i for i in filt_txt if re.match(pat, i)]\n",
    "            if len(taboo_ids) == 0: \n",
    "                no_ent.append(1)\n",
    "                only_ent.append(0)\n",
    "            else: \n",
    "                no_ent.append(0)\n",
    "                if len(taboo_ids) == len_text: \n",
    "                    only_ent.append(1)\n",
    "                elif len(filt_txt2) == 0:\n",
    "                    only_ent.append(1)\n",
    "                else: \n",
    "                    only_ent.append(0)\n",
    "\n",
    "        return only_ent, no_ent\n",
    "    \n",
    "    def filter_sentences_correctness (self, true_labels, pred_labels): \n",
    "        correct_ent_ids = []\n",
    "        correct_ent_tags = []\n",
    "        only_wrong = []\n",
    "\n",
    "        for a,b in zip(true_labels, pred_labels): \n",
    "            a2ids, a2tags = self.get_entities(a) ##correct entities\n",
    "            c = 0 ##counter for how many correct\n",
    "            nw_entids= []\n",
    "            nw_enttags= []\n",
    "            for ent, enttag in zip(a2ids, a2tags): ##per correct entity check \n",
    "                c2 = 0 \n",
    "                start = ent[0]\n",
    "                end = ent[-1]\n",
    "                if end == start: \n",
    "                    b2 = b[start:(start+1)]\n",
    "                else: \n",
    "                    b2 = b[start:(end+1)]\n",
    "                if b2 == enttag: ##definitely correct if the same\n",
    "                    c =+1 \n",
    "                    c2 =+ 1\n",
    "                else: \n",
    "                    btag = enttag[0]\n",
    "                    s = set(b2)\n",
    "                    if btag in s: #if the B-tag is correct then it is not completely wrong / missing\n",
    "                        c =+ 1\n",
    "                        c2 =+ 1\n",
    "                    else: \n",
    "                        pass\n",
    "                if c2 > 0: \n",
    "                    nw_entids.append(ent)\n",
    "                    nw_enttags.append(enttag)\n",
    "\n",
    "            if c == 0:  ##no correct at all\n",
    "                only_wrong.append(1) ##there is no correct entity \n",
    "#                 correct_ent_ids.append(None)\n",
    "            else: \n",
    "                only_wrong.append(0) ##there is at least one correct entity\n",
    "            correct_ent_ids.append(nw_entids)\n",
    "            correct_ent_tags.append(nw_enttags)\n",
    "\n",
    "        return only_wrong, correct_ent_ids, correct_ent_tags\n",
    "    \n",
    "    def filter_unfit(self,true_labels, sents, ids, only_ent, no_ent): \n",
    "        remove = []\n",
    "        ##remove unfit\n",
    "        for a,b in zip(only_ent, no_ent): \n",
    "            if a==1 or b==1: \n",
    "                remove.append(1)\n",
    "            else:\n",
    "                remove.append(0)\n",
    "        \n",
    "        nw_sents = [i for num, i in enumerate(sents) if remove[num] == 0]\n",
    "        nw_true_labels = [i for num, i in enumerate(true_labels) if remove[num] == 0]\n",
    "        nw_ids = [i for num, i in enumerate(ids) if remove[num] == 0]\n",
    "        \n",
    "        return nw_sents, nw_true_labels, nw_ids\n",
    "    \n",
    "    def filter_unfit_r2 (self, true_labels, sents, ids, correct_ent_ids, correct_ent_tags, preds_list, only_wrong): \n",
    "        nw_sents = [i for num, i in enumerate(sents) if only_wrong[num] == 0]\n",
    "        nw_true_labels = [i for num, i in enumerate(true_labels) if only_wrong[num] == 0]\n",
    "        nw_ids = [i for num, i in enumerate(ids) if only_wrong[num] == 0]\n",
    "        nw_cor_ent_ids = [i for num, i in enumerate(correct_ent_ids) if only_wrong[num] == 0]\n",
    "        nw_cor_ent_tags = [i for num, i in enumerate(correct_ent_tags) if only_wrong[num] == 0 ]\n",
    "        nw_preds_list = [i for num, i in enumerate(preds_list) if only_wrong[num] == 0 ] \n",
    "        \n",
    "        return nw_true_labels, nw_sents, nw_ids, nw_cor_ent_ids, nw_cor_ent_tags, nw_preds_list\n",
    "        \n",
    "    \n",
    "    def main(self, data, modelpath, savepath, savepath2, labelfile='labels.txt', devdata= None, traindata= None, alltestdata=None, random_attack = False, make_first_prediction= False, entities = False, sim_synonyms=0.5, sim_score_threshold= 0.8): \n",
    "#         print(sim_score_threshold)\n",
    "        self.initialize_essential(entities)\n",
    "        already_fully_wrong = [] #no need to break\n",
    "        not_fit_for_adversarial = [] # no words besides entities and stopwords \n",
    "\n",
    "        self.initialize_model(modelpath, labelfile)\n",
    "        \n",
    "        ##get sents and labels -- input data needs to be a aggregated df (grouped by id)\n",
    "        sents = list(data['words'])\n",
    "        true_labels = list(data['ner'])\n",
    "        try: \n",
    "            ids = list(data['id'])\n",
    "        except KeyError: \n",
    "            ids = list(data.index.values)\n",
    "        \n",
    "        ##first filter for if sentences either miss entities or miss changeable words - there is nothing to change\n",
    "        if entities == False: \n",
    "            only_ent, no_ent = self.identify_unfit_sents (true_labels, sents)\n",
    "\n",
    "            only_ent_ids = [i for num, i in enumerate(ids) if only_ent[num] == 1]\n",
    "            no_ent_ids = [i for num, i in enumerate(ids) if no_ent[num] == 1]\n",
    "\n",
    "            nw_sents, nw_true_labels, nw_ids = self.filter_unfit (true_labels, sents, ids, only_ent, no_ent)\n",
    "    #         print(nw_sents[0])\n",
    "        else:\n",
    "            nw_sents = sents\n",
    "            nw_true_labels = true_labels\n",
    "            nw_ids = ids\n",
    "            only_ent_ids =[]\n",
    "            no_ent_ids = []\n",
    "            \n",
    "        #make or cache first_prediction\n",
    "        if make_first_prediction== True: \n",
    "            print(self.labels)\n",
    "            results, preds_list, probs, preds, old_preds_list, true_labelsx, label_map = self.first_prediction(nw_sents, nw_true_labels)\n",
    "            self.save_obj(preds_list,'first_preds_list')\n",
    "            self.save_obj(probs,'first_probs')\n",
    "        else: \n",
    "            preds_list = self.load_obj('first_preds_list')\n",
    "            probs = self.load_obj('first_probs')\n",
    "            \n",
    "        if entities == False:\n",
    "            sp1 = savepath2 + 'first_results_context'\n",
    "            save_obj(results, sp1)\n",
    "            sp2 = savepath2 + 'first_predictions_context'\n",
    "            save_obj(preds_list, sp2)\n",
    "            sp3 = savepath2 + 'first_probs_context'\n",
    "            save_obj(probs, sp3)\n",
    "            sp4 = savepath2 + 'only_ents'\n",
    "            save_obj(only_ent_ids, sp4)\n",
    "        \n",
    "        if entities == True:\n",
    "            sp1 = savepath2 + 'first_results_entities'\n",
    "            save_obj(results, sp1)\n",
    "            sp2 = savepath2 + 'first_predictions_entities'\n",
    "            save_obj(preds_list, sp2)\n",
    "            sp3 = savepath2 + 'first_probs_entities'\n",
    "            save_obj(probs, sp3)\n",
    "        \n",
    "        ##second filter -do not need to change if they are already wrong (if some of entities are wrong only those are changed)\n",
    "        \n",
    "        only_wrong, correct_ent_ids, correct_ent_tags = self.filter_sentences_correctness (nw_true_labels, preds_list)\n",
    "         \n",
    "        only_wrong_ids = [i for num, i in enumerate(nw_ids) if only_wrong[num] == 1]\n",
    "        \n",
    "        nwer_true_labels, nwer_sents, nwer_ids, correct_ent_ids, correct_ent_tags, nw_preds_list = self.filter_unfit_r2 (nw_true_labels, nw_sents, nw_ids, correct_ent_ids, correct_ent_tags, preds_list, only_wrong)\n",
    "        \n",
    "#         print(len(nw_preds_list))\n",
    "\n",
    "        if entities == True: \n",
    "            sp1 = savepath2 + 'only_wrong_ids'\n",
    "            save_obj(only_wrong_ids, sp1)\n",
    "        \n",
    "        out_texts = []\n",
    "        \n",
    "        if entities == False: \n",
    "            if random_attack == False:\n",
    "                for num, sent in enumerate(nwer_sents):\n",
    "                        \n",
    "                        print(sent)\n",
    "                        ##initialize\n",
    "                        print(num +1)\n",
    "                        print(len(nwer_sents))\n",
    "                        predlbl = nw_preds_list[num]\n",
    "                        origlbl = nwer_true_labels[num]\n",
    "                        ent_tags = correct_ent_tags[num]\n",
    "                        ent_ids = correct_ent_ids[num]\n",
    "\n",
    "                        ##run\n",
    "                        out_text = self.get_adversarial_examples_per_sent(sent, origlbl, predlbl, ent_tags, ent_ids, sim_synonyms = 0.5, sim_score_threshold = 0.8) \n",
    "#                         print(out_text)\n",
    "                        out_texts.append(out_text)\n",
    "\n",
    "                        save_obj(out_texts,savepath)\n",
    "            else:\n",
    "                for num, sent in enumerate(nwer_sents):\n",
    "                     ##initialize\n",
    "                    print(num + 1)\n",
    "                    print(len(nwer_sents))\n",
    "                    predlbl = nw_preds_list[num]\n",
    "                    origlbl = nwer_true_labels[num]\n",
    "                    ent_tags = correct_ent_tags[num]\n",
    "                    ent_ids = correct_ent_ids[num]\n",
    "                    print(ent_tags)\n",
    "                    \n",
    "                   \n",
    "                    ##run \n",
    "                    out_text = self.get_adversarial_examples_per_sent(sent, origlbl, predlbl, ent_tags, ent_ids, random_attack = True, sim_synonyms = sim_synonyms, sim_score_threshold = sim_score_threshold) \n",
    "                    out_texts.append(out_text)        \n",
    "                    save_obj(out_texts,savepath)\n",
    "                                       \n",
    "            \n",
    "        if entities == True:\n",
    "            taglst, allent = self.retrieve_entities(devdata, traindata, alltestdata)\n",
    "            for num, sent in enumerate(nwer_sents):\n",
    "                 ##initialize\n",
    "                print(num + 1)\n",
    "#                 if num > 10: \n",
    "#                     break\n",
    "                print(sent)\n",
    "                predlbl = nw_preds_list[num]\n",
    "                origlbl = nwer_true_labels[num]\n",
    "                ent_tags = correct_ent_tags[num]\n",
    "                ent_ids = correct_ent_ids[num]\n",
    "                \n",
    "                ##run\n",
    "                out_text = self.get_adversarial_sent_entities (sent, origlbl, predlbl, ent_tags, ent_ids, taglst, allent, sim_score_threshold=sim_score_threshold) \n",
    "                out_texts.append(out_text)\n",
    "                save_obj(out_texts,savepath)\n",
    "        if entities == None: \n",
    "#             for num, sent in enumerate(nwer_sents):\n",
    "#             out_texts = []\n",
    "            return only_ent_ids, no_ent_ids, only_wrong_ids, nwer_sents, results\n",
    "\n",
    "        return only_ent_ids, no_ent_ids, only_wrong_ids, out_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNUT\n"
     ]
    }
   ],
   "source": [
    "##loading data \n",
    "\n",
    "path = '/data/WNUT_AdversarialSample.tsv'\n",
    "test = pd.read_csv(path, sep = '\\t')\n",
    "\n",
    "devdata= pd.read_csv('/data/WNUT_devdata.tsv', sep = '\\t')\n",
    "traindata = pd.read_csv('/data/WNUT_traindata.tsv', sep = '\\t')\n",
    "testdata = pd.read_csv('/data/WNUT_testdata.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE OF ENTITY ATTACK -- entities argument set to True\n",
    "\n",
    "modelpath = '/NER_data/WNUT/bert_e4_lr5/'\n",
    "\n",
    "##The first save path is for the adversarial sentences \n",
    "savepath = '/NER_data/WNUT/BERT1/output_bert1_entity'\n",
    "\n",
    "##The second save path is other output\n",
    "savepath2 = '/NER_data/WNUT/BERT1/'\n",
    "\n",
    "only_ent_ids, no_ent_ids, only_wrong_ids, out_texts = AdversarialBERT().main(test, modelpath,savepath, savepath2, 'labels.txt', devdata2, traindata2, testdata2, random_attack =False, make_first_prediction= True, entities = True)\n",
    "\n",
    "##only ent ids are those sentences with only entities and no other words -- not relevant for entity attack \n",
    "## no ent ids are those sentences without any entities - EXCLUDED FROM ENTITY ATTACK\n",
    "## only wrong ids are those sentences with only wrong predictions of entities - EXCLUDED FROM ENTITY ATTACK \n",
    "\n",
    "## out texts are the provided adversarial sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CONTEXT ATTACK -- entities argument set to False\n",
    "\n",
    "modelpath = '/NER_data/WNUT/bert_e4_lr5/'\n",
    "\n",
    "##The first save path is for the adversarial sentences \n",
    "savepath = '/NER_data/WNUT/BERT1/output_bert1_context'\n",
    "\n",
    "##The second save path is other output\n",
    "savepath2 = '/NER_data/WNUT/BERT1/'\n",
    "\n",
    "only_ent_ids, no_ent_ids, only_wrong_ids, out_texts = AdversarialBERT().main(test, modelpath,savepath, savepath2, 'labels.txt', devdata, traindata, testdata, random_attack =False, make_first_prediction= True, entities = False)\n",
    "\n",
    "##only ent ids are those sentences with only entities and no other words -- EXCLUDED FROM CONTEXT ATTACK\n",
    "## no ent ids are those sentences without any entities - EXCLUDED FROM CONTEXT ATTACK\n",
    "## only wrong ids are those sentences with only wrong predictions of entities - EXCLUDED FROM CONTEXT ATTACK \n",
    "\n",
    "## out texts are the adversarial sentences.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
